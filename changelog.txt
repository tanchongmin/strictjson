2 Apr 2025 (v6.1.1)
- Fixed backslash single quotes in parse_yaml by replacing them with double single quotes ('') for better yaml parsing (credit: hornwijaya)
- Added awaitable as a requirement for llm in parse_yaml_async
- Enum is now output as a value instead of as an Enum instance
- Added in a way to check whether **kwargs is present in llm input variable - if so, then pass system_prompt, user_prompt and **kwargs into it. Otherwise, only pass in system_prompt and user_prompt.
- Included an additional example for invoice extraction in Tutorial - parse_yaml.ipynb
- Fixed empty string parsing for `strict_json` and `strict_json_async`, and also key and value names enclosed with ` (a trait of gpt-4o-mini - this is non-standard json output, but we need to cater for this as well)

13 Mar 2025 (v6.1.0)
- HUGE Update: `parse_yaml`
- `parse_yaml` now does not need exec() to create pydantic model, as it does compositional model creation programmatically, making it safer to use
- Prompt for `parse_yaml optimised for a lot of common models:
    - Claude 3.5 Sonnet
    - Claude 3.7 Sonnet
    - gpt-o3-mini
    - gpt-o1-mini
    - gpt-4o-mini
    - gpt-4o
    - Meta Llama 3.3 70B
    - Meta Llama 3.2 90B (Note: Smaller versions of Llama 3.2 do not work well with YAML)
    - Meta Llama 3.1 70B (Note: Smaller versions of Llama 3.1 do not work well with YAML)
    - DeepSeek-V3
    - DeepSeek-R1
    - QwW 32B
    - Gemini 2.0 Flash
    - Gemini 2.0 Flash-Lite
- Provided a convenient interface to either use `output_format` or `pydantic_model` to directly interface with LLM provider's structured output parser (if needed)
- Removed `functions.py` and `utils.py` in order to retain only the essentials - LLM parsing - for strictjson repo
- `parse_yaml` will now be the main focus for development, `strict_json` is still around for legacy compatibility only

21 Feb 2025 (v6.0.0)
- HUGE Update: Now comes with `parse_yaml` and `parse_yaml_async` function
- Uses the same type checking and output_format as `strict_json`, with optional `type: ` parameter
- Added `pydantic` to `requirements.txt`
- # Why YAML?
- YAML is much more concise than JSON, and avoids a lot of problems faced with quotations and brackets
- YAML also outputs code blocks much better with multi-line literal-block scalar (|), and the code following it can be totally free of any unnecessary backslash escape characters as it is not in a string
- LLMs now are quite good at interpreting YAML than when this repo was first started
- # How it works
- Parses the LLM output as a YAML, and converts it to dict
- Uses concise `output_format` to save tokens
- Converts `output_format` into pydantic schema automatically, and uses pydantic to validate output
- Able to process datatypes: `int`, `float`, `str`, `bool`, `list`, `dict`, `date`, `datetime`, `time`, `UUID`, `Decimal`
- Able to process: `None`, `Any`, `Union`, `Optional`
- Default datatype when not specified is `Any`
- Error correction of up to `num_tries` times (default: 3)

5 Aug 2024 (v5.1.3)
- Removed dependencies for TaskGen Memory module. Now only has one dependency in requirements.txt: asyncio
- Removed dependencies for openai, as this will is LLM-specific

25 Jul 2024 (v5.1.1)
- Fixed a missing filter for strict_json_async to get only the text within {} for json
- For strict_json, changed the output to be f'''\nOutput in the following json template: ```{new_output_format}```
Update values enclosed in <> and remove the <>. 
Your response must only be the updated json template beginning with {{ and ending with }}
Ensure the following output keys are present in the json: {' '.join(list(new_output_format.keys()))}'''

This helps by changing ['###key###'] into ###key### , which helps Llama 3 8B better understand how to format the json

- Changed all default model parameters in Tutorial Notebooks and code to be 'gpt-4o-mini' instead of 'gpt-3.5-turbo' for cheaper and better performance

10 Jul 2024 (v5.1.0)
- Updated strict_json prompt to be f'''\nOutput in the following json template: ```{new_output_format}```
Update values enclosed in <> and remove the <>. 
Your response must only be the updated json template beginning with {{ and ending with }}
Ensure the following output keys are present in the json: {list(new_output_format.keys())}'''
This will help smaller models like Llama 3 8B generate more reliably.
- Amended the Tutorial to fix some issues where llm variable was not called

5 Jul 2024 (v5.0.0)
- HUGE: Async support added. Added async_chat, async_strict_json, FunctionAsync
- Changed prompt of strict_json to make it compatible with more LLMs: 
    '''\nOutput using the following json template: {new_output_format}
Update values enclosed in <> and remove the <>. 
Output only a valid json beginning with {{ and ending with }} and ensure that the following keys are present: {list(new_output_format.keys())}'''
- `Function()` now allows just automatically inferring the `fn_description` and `output_format` from external function, using `Function(external_fn = fn)`
- By default, strictjson will not decode for all unicode escapes, just \\t, \\n, \\' and \\". Using type: code will do for all unicode escapes
- type: code now converts python```code``` -> code, which makes it more versatile for LLM code generation
- Added in dependencies: langchain, PyPDF2, python-docx, pandas, xlrd. These are for document processing in memory for TaskGen (but added to also provide features of TaskGen repo)
- Edited the `convert_to_dict` function in `base.py` to make it more robust to variations of incorrect keys, edited error message for incorrect key to make it more robust

5 May 2024 (v4.1.0)
- Changed prompt of strict_json to make it compatible with more LLMs and improve performance on ChatGPT: 
    '''\nOutput in the following json string format: {new_output_format}
    Update text enclosed in <>. Output only a valid json string beginning with {{ and ending with }}'''
- Added more external LLM examples in Tutorial

22 Apr 2024 (v4.0.1)
- Changed StrictJSON prompt to make it better: Added "You must output valid json with all keys present." to system prompt of `strict_json` to make it more robust
- Modified openai>=1.3.6 to requirements.txt so that it is compatible with newer versions of LangChain
- Added dill>=0.3.7 to requirements.txt so that the agentic part can run on Colab
- Added return_as_json = True as an input variable to strict_json (default: False, so it will be a python dictionary), so that you can get the json string as output if needed. Works also for OpenAIJson mode

4 Mar 2024 (v4.0.0)
- Better parsing that caters for newlines and extra spaces for nested datatypes
- Changed the dictionary parsing of StrictJSON to ensure that we extract the leftmost and rightmost { and } respectively to do ast.literal_eval. Previously might have the quotation marks at the left and right which affected parsing
- Changed the bool parsing of StrictJSON to convert true/false to True/False first so as to make it parseable by ast.literal_eval
- Made list processing in StrictJSON more robust
- Moved Agentic Framework entirely to TaskGen

16 Feb 2024 (v3.0.2)
- Added select_function and use_function to do manual function usage for agents

15 Feb 2024 (v3.0.1)
- Added Agent.ipynb, a tutorial for agents
- Added StrictJSON Agents which are initialisable with name and description
- Agents can take in functions of class `Function`
- Agents can run(task) and also assign(task) and step() through them
- Modified `Function` to cater for external functions as well
- Added a fn_name in `Function` which will be the name of parameter (if provided), or name of the external function (if provided), otherwise it will be inferred by LLM from fn_description
- Added in `bool` type forcing to `strict_json`

9 Feb 2024 (v2.2.2)
- Exposed the LLM variable so user can use any llm they want
- changed `strict_function` naming to `Function` to match convention of class names being capitalised (`strict_function` still works for legacy support.)
- added legacy support for `strict_text` and `strict_output`, which were the earlier function names of the current `strict_json`
- Variables for `Function` now enclosed in <> in `fn_description` for better performance

8 Feb 2024 (v2.2.1)
- Added in LLM-based checks by using type: ensure <requirement> in output field
- Added in custom_checks and check_data in strict_json for user to implement their own custom check functions

5 Feb 2024 (v2.2.0)
- HUGE: Nested output formats of multiple lists and dictionaries are now supported!
- Now supports int, float, str, dict, list, Dict[], List[], Enum[] type forcing with LLM-based error correction
- Better handling of naming of variables in strict_function by using list of variables using variable_names
- Removed input_type and output_type from strict_function. Reason: input_type not needed as LLMs can flexibly perceive inputs, output_type is now handled with type forcing

8 Jan 2024 (v2.0.2)
- Installable by pip
- Support for OpenAI JSON Mode
- StrictJSON Functions